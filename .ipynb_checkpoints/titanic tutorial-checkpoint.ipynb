{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックではpythonによるtitanicデータ処理の基本を勉強していきます。<br>\n",
    "なおここでは、titanic_datasフォルダにデータがあると仮定して進めます。kaggleのkernelを使用している場合、データは../input/にあるので、データのパスをtitanic_darasから../inputに変更してください\n",
    "\n",
    "<h1>1. データの相関</h1>\n",
    "\n",
    "まず最初に、<b>pandas</b>というデータ処理用のライブラリを用いてデータを読み込んでみましょう。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bb0646d5d67b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mread_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"titanic_datas/train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdependency\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhard_dependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdependency\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdependency\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;31m# no-one else in the world is using it (though I hope not)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTester\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnosetester\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_tester\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m     \u001b[0mbench\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnosetester\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_tester\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbench\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testing' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "read_data = pandas.read_csv(\"titanic_datas/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "無事にデータを読み込むことはできたでしょうか？できたか確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もしうまく読み込めていたら、表のようなものが出力されていると思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>titanicではどのような人が優先的に救助されたのでしょうか？</b><br>\n",
    "レディーファーストで、若い女性が優先されて救助されたのは間違いないでしょう。では、生存率を見てみましょう、実際にそうだったのでしょうか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_data = read_data[read_data.Sex == \"male\"]\n",
    "print(len(male_data[male_data.Survived == 1]) / len(male_data))\n",
    "\n",
    "female_data = read_data[read_data.Sex == \"female\"]\n",
    "print(len(female_data[female_data.Survived == 1]) / len(female_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これから女性の生存率がはるかに高いことがわかります。<br>\n",
    "\n",
    "<b>ではほかの要素はどうでしょうか？例えば年齢などは関係してくるのでしょうか？</b><br>\n",
    "試しにグラフを書いてみましょう。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "split_data = []\n",
    "for survived in [0,1]:\n",
    "    split_data.append(read_data[read_data.Survived==survived])\n",
    "\n",
    "temp = [read_data.Age.dropna() for i in split_data]\n",
    "plt.hist(temp, histtype=\"barstacked\", bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>グラフだと若いと生存率が高いように見えます。本当でしょうか？</b><br>\n",
    "割合を見てみましょう。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data.Age.fillna(read_data.Age.median(), inplace=True)\n",
    "age_list = list(set(map(int, read_data.Age)))\n",
    "age_list.sort()\n",
    "age_per = list()\n",
    "for i in age_list:\n",
    "    age_data = read_data[read_data.Age == i]\n",
    "    if len(age_data) != 0:\n",
    "        age_per.append(len(age_data[age_data.Survived == 1]) / len(age_data))\n",
    "        print(i, len(age_data[age_data.Survived == 1]) / len(age_data))\n",
    "    else:\n",
    "        age_per.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、fillnaメソッドでは、年齢の中央値でNanを埋めています。<br>\n",
    "\n",
    "<b>なぜ、平均値ではなく中央値なのでしょうか？</b><br>\n",
    "それは平均値は極端に大きいか小さい値(外れ値)に引き寄せられる性質があるためです。<br>\n",
    "中央値は全データの中心の値なのでデータの大きさによりません。なので平均値ではなく中央値を使っているのです。\n",
    "\n",
    "これを折れ線グラフにしてみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(age_list, age_per)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このグラフから、年齢が低いもしくは高い人の生存率が高いことがわかります。<br>\n",
    "\n",
    "<h1>2. データの解析</h1>\n",
    "\n",
    "さて、ここまでで、性別および年齢と、生存率の相関がわかりました。<br>\n",
    "各変数と生存率の相関を見るのはここまでにして、次はデータの解析を行っていきましょう。なお、以下では性別、年齢、社会的階級が生存と関係していたと仮定して話を進めます。\n",
    "\n",
    "<h2>2.1. ランダムフォレストとサポートベクトルマシン</h2>\n",
    "\n",
    "この章では、ランダムフォレストとサポートベクトルマシンの仕組みおよび実装の説明をしていきます。<br>\n",
    "まず最初に、<b>ランダムフォレスト</b>のもととなる<b>決定木</b>という手法について説明と実装を行っていきましょう。<br>\n",
    "\n",
    "決定木とは、簡単に言えば、データを元にしてデータを分類するルールを作っていく手法です。<br>\n",
    "では、どのようにして分類するルールを決定しているのでしょうか？それを今から見ていきましょう。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.1.1. 決定木</h3>\n",
    "\n",
    "物事を決定するとき、<b>決定しやすい情報</b>がほしいと思います。<br>\n",
    "\n",
    "例えば、「政治家」という情報だけでどの政治家であるかを断定するのは難しいでしょう。しかし、これが「大統領」だとどうでしょうか？一気に候補に挙がる人が少なくなるかと思います。<br>\n",
    "このように、得た情報によって物事の決定のしやすさが大きく変わる事が分かると思います。<br>\n",
    "\n",
    "コンピュータが人間のように物事を決定できたら楽なのですが、コンピュータは計算しかできないので、どうにかして「情報の大きさ」というものを数学的に表す必要があります。<br>\n",
    "実はこのようなものを表すのに最適な数学の道具があります。それが<b>情報量</b>です。<br>\n",
    "\n",
    "情報量Iはつぎのように定義される量です。<br>\n",
    "$$\n",
    "\\begin{equation*}\n",
    "I = -log P(x)\n",
    "\\end{equation*}\n",
    "$$\n",
    "ここでP(x)はxが起きる確率を表しています。<br>\n",
    "何故このような式になるのかは、深く考えないようにしてください。「あぁ、数学ではこうやって情報の大きさを表すんだな」という理解だけで十分です。<br>\n",
    "\n",
    "情報量はある物事が起きた時に得られる情報の大きさを表しています。しかし、ここで欲しいのは<b>「一回情報を取得した時に得られる情報の期待値を最小にする物事」です。</b><br>\n",
    "なぜこれを最小にしたいのでしょうか？先ほどの例を引き合いに出して考えると、政治家の母数よりも大統領の母数のほうが少ないですよね？このような情報では当然得られる情報量は少ないでしょう。つまり、情報量が少なくなるように情報を選ぶと、少ない回数で物事を決定できるのです。<br>\n",
    "\n",
    "では、一回に得られる情報量の期待値とは、どのように計算したら良いでしょうか？\n",
    "\n",
    "ここで一度<b>期待値</b>を思い出してみましょう。<br>\n",
    "期待値を覚えていますか？覚えていない方もいるかもしれませんが大丈夫です、これから思い出しましょう。<br>\n",
    "期待値Eとはある事象Xに対する確率P(X)とある事象Xに対応する関数の値f(X)に対して\n",
    "$$\n",
    "\\begin{equation*}\n",
    "E= \\sum_{X}^{}P(X)f(X)\n",
    "\\end{equation*}\n",
    "$$\n",
    "で表せる量です。<br>\n",
    "これは一回物事が起きた時に得られる平均のf(X)の値を表しています。<br>\n",
    "\n",
    "つまりこれに先ほどの情報量の定義式を入れれば一回に得られる平均の情報量Hがわかることになります。したがって\n",
    "$$\n",
    "\\begin{equation*}\n",
    "H = \\sum_{X}^{} -P(X)log P(X)\n",
    "\\end{equation*}\n",
    "$$\n",
    "を得ます。これを平均情報量(エントロピー)といいます。\n",
    "\n",
    "以上をふまえて、まずはエントロピーを計算する関数を作ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(probabilities):\n",
    "    return sum(-p * math.log(p,2) for p in probabilities if p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どうでしょうか？ただ式をプログラムにするだけなので難しくなかったと思います。難しかったという方も大丈夫、僕もこれを書くとき悩みましたから。<br>\n",
    "\n",
    "このプログラムでは確率を用います。なので、データからあるデータが出てくる確率を計算する関数を作ってみましょう。<br>\n",
    "ここで注意が必要で、<b>確率の総和は1でなければなりません。</b>ここだけは注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probabilities(labels):\n",
    "    total_count = len(labels)\n",
    "    return [count / total_count for count in Counter(labels).values()]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これもそこまで難しくないかと思います。<b>ただし、Counterというクラスを使用していることに注意してください。</b>これは組み込み型で、Pythonで集計などを行うときに便利な型なので、覚えておくと良いかもしれません。\n",
    "\n",
    "ここまでで、エントロピーを計算する関数と、確率を計算するプログラムができました。次に、データを受け取り、そのデータから各データのエントロピーを計算するプログラムを書いてみましょう。\n",
    "ここではひとまず、データの構造は、最初にtuple型でデータ、次に答えを受け取るtuple型のlistとします。\n",
    "\n",
    "    [\n",
    "        (data, answer),\n",
    "        (data, answer),\n",
    "        ...\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_entropy(labeled_data):\n",
    "    labels = [label for _, label in labeled_data]\n",
    "    p = probabilities(labels)\n",
    "    return entropy(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、分割されたデータのエントロピーを計算しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_entropy(subsets):\n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "    return sum(data_entropy(subset) * len(subset) / total_count for subset in subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続いて、与えられたキーでデータを分割する関数を作ってみましょう。つまり<br>\n",
    "\n",
    "    [\n",
    "        {1:2, 2:3}\n",
    "        {1:3, 2:6}\n",
    "        {1:2, 2:5}\n",
    "    ]\n",
    "    \n",
    "というデータが与えられたとき、この関数にキーである1を与えると<br>\n",
    "\n",
    "    {\n",
    "    2:[{1:2, 2:3}, {1:2, 2:5}],\n",
    "    4:[{1:3, 2:6}],\n",
    "    }\n",
    "    \n",
    "などと帰ってくる関数です。なお、与えられたキーに対応するデータを、出力のdictのキーとします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_by(inputs, attribute):\n",
    "    groups = dict()\n",
    "    for input in inputs:\n",
    "        key = input[0][attribute]\n",
    "        if not key in groups:\n",
    "            groups[key] = list()\n",
    "        groups[key].append(input)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでで、分割されたデータのエントロピーの計算、データの分割まで関数を作成しました。<br>\n",
    "次に与えられたキーでデータを分割し、分割したデータのエントロピーを計算する関数を作ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcurate_entropy(inputs, attribute):\n",
    "    partitions = partition_by(inputs, attribute)\n",
    "    #print(partitions.values())\n",
    "    return partition_entropy(partitions.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ではこれらはきちんと動くのでしょうか？<br>\n",
    "実際に年齢と性別のエントロピーを計算して確認してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "\n",
    "data_key =[\"Age\",\"Sex\"]\n",
    "\n",
    "train = [({key:read_data.T[index][key] for key in data_key}, read_data.T[index][\"Survived\"]) for index in read_data.T]\n",
    "\n",
    "for key in data_key:\n",
    "    print(key, calcurate_entropy(train, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "何らかの値が計算できたと思います。<br>\n",
    "最初に書いてあるように、エントロピーが最小になるようにルールを決定したらよいので、この場合最初に性別で分けるのが良いことがわかります。\n",
    "\n",
    "ここまでで、ルールを決定する方法を説明しました。<br>\n",
    "しかしこれらのルールをいちいち計算して、人間の手で作成していくのは非効率的です。<br>\n",
    "なのでルールを自動的に計算する関数を再帰を使って作りましょう。\n",
    "\n",
    "手順としては、まずデータ数、Survivedが1であるデータ数、Survivedが0であるデータ数を計算します。<br>\n",
    "\n",
    "Survivedが0,1であるデータ数のどちらかが0になったとき、データが決定されるので、ここでそのルールの生成を止めます。<br>\n",
    "もしsplit_candidatesがFalseの場合、つまり分割の候補がない場合、より多いデータを返します。\n",
    "\n",
    "それ以外の時、最小のエントロピーを持つキーでルールを生成したらよいので、最小のエントロピーを持つキーを計算します。<br>\n",
    "そして、その最小のキーの中に存在するデータを分割し、分割したデータをもとに、そのデータからさらにルールの生成などを再帰的に行うことで自動生成ができます。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def build_tree(inputs, split_candidates=None):\n",
    "    if split_candidates is None:\n",
    "        split_candidates = inputs[0][0].keys()\n",
    "    \n",
    "    num_inputs = len(inputs)\n",
    "    num_1 = len([label for item, label in inputs if label == 1])\n",
    "    num_0 = num_inputs - num_1\n",
    "    \n",
    "    if num_1 == 0:\n",
    "        return 0\n",
    "    if num_0 == 0:\n",
    "        return 1\n",
    "    if not split_candidates:\n",
    "        return 1 if num_1 >= num_0 else 0\n",
    "    \n",
    "    best_attribute = min(split_candidates, key=partial(calcurate_entropy, inputs))\n",
    "    \n",
    "    partitions = partition_by(inputs, best_attribute)\n",
    "    new_candidates = [a for a in split_candidates if a != best_attribute]\n",
    "    \n",
    "    sub_trees = {attribute_value : build_tree(subset, new_candidates) for attribute_value, subset in partitions.items()}\n",
    "    sub_trees[None] = 1 if num_1 > num_0 else 0\n",
    "    \n",
    "    return best_attribute, sub_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、決定木を作ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = build_tree(train)\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これをもとにデータを分類してみたいと思います。\n",
    "そのために、分類木とデータからデータを分類する関数を作ってみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(tree, input):\n",
    "    if tree in [0, 1]:\n",
    "        return tree\n",
    "    \n",
    "    attribute, subtree_dict = tree\n",
    "    subtree_key = input.get(attribute)\n",
    "    \n",
    "    if not subtree_key in subtree_dict:\n",
    "        subtree_key = None\n",
    "    \n",
    "    subtree = subtree_dict[subtree_key]\n",
    "    return classify(subtree, input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この関数にデータを入れましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_test_data = pandas.read_csv(\"titanic_datas/test.csv\")\n",
    "\n",
    "input_data = [{key:read_data.T[index][key] for key in data_key} for index in read_data.T]\n",
    "result = [classify(tree, input_data[i]) for i in range(len(read_test_data))]\n",
    "\n",
    "read_test_data[\"Survived\"] = result \n",
    "read_test_data[[\"PassengerId\",\"Survived\"]].to_csv(\"titanic_datas/submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.1.2. ランダムフォレスト</h3>\n",
    "\n",
    "<b>ここまでで、提出用のデータまで作成することができました。</b><br>\n",
    "\n",
    "しかし、提出はちょっと待ってください。これを提出しても0.55くらいのスコアしか出ません。<br>\n",
    "なぜかというと、この学習したデータのみに適応した決定木が作成されているためです。<br>\n",
    "これに対してどのように対処したらよいでしょうか？\n",
    "\n",
    "実はこれに対応するために作られたアルゴリズムがあります、それが<b>ランダムフォレスト</b>です。<br>\n",
    "ではランダムフォレストはどのように実装したらよいでしょうか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_forest(trees, input):\n",
    "    votes = [classify(tree, input) for tree in trees]\n",
    "    vote_counts = Counter(votes)\n",
    "    return vote_counts.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今まで自分でコードを書いてきました。しかし、pythonにおいて重要なことが一つあります。<br>\n",
    "それはpythonで何かやりたいとき、まず最初にやりたいことをするライブラリがあるか探そうというものです。<br>\n",
    "今回、決定木やランダムフォレストを実装しましたが、これらもライブラリが存在します。<br>\n",
    "それが機械学習についての関数やクラスをまとめた<b>scikit-learn</b>です。\n",
    "\n",
    "ではscikit-learnを使ってランダムフォレストを実装して、結果をsubmitしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "read_data = read_data.replace(\"male\", 0).replace(\"female\", 1)\n",
    "read_data[\"Age\"].fillna(read_data.Age.median(), inplace=True)\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(read_data[data_key], read_data[\"Survived\"])\n",
    "\n",
    "read_test_data = pandas.read_csv(\"titanic_datas/test.csv\").replace(\"male\", 0).replace(\"female\", 1)\n",
    "read_test_data[\"Age\"].fillna(read_test_data.Age.median(), inplace=True)\n",
    "\n",
    "pre =  forest.predict(read_test_data[data_key])\n",
    "read_test_data[\"Survived\"] = pre\n",
    "read_test_data[[\"PassengerId\",\"Survived\"]].to_csv(\"titanic_datas/submission_scikit_random_forest.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVMについてはそのうち書きます。以下がSVMの場合のコードです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvc = LinearSVC()\n",
    "lsvc.fit(read_data[data_key], read_data[\"Survived\"])\n",
    "\n",
    "read_test_data = pd.read_csv(\"titanic_datas/test.csv\").replace(\"male\",0).replace(\"female\",1)\n",
    "\n",
    "test_data[\"Age\"].fillna(train_data[\"Age\"].median(), inplace=True)\n",
    "\n",
    "pre = lsvc.predict(test_data[target])\n",
    "read_test_data[\"Survived\"] = pre\n",
    "read_test_data[[\"PassengerId\",\"Survived\"]].to_csv(\"titanic_datas/submission_scikit_suport_vector_machine.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
